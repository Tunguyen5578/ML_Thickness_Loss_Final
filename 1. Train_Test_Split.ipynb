{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split - Pipeline Thickness Loss Dataset\n",
    "## TASK 5: Baseline Evaluation - Data Splitting\n",
    "\n",
    "**Date:** December 30, 2025  \n",
    "**Dataset:** thickness_loss_dataset_engineered.csv  \n",
    "**Split Ratio:** 80/20 (Train/Test)  \n",
    "**Random State:** 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T00:16:04.023028500Z",
     "start_time": "2025-12-31T00:15:58.802449100Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('✓ Libraries loaded')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries loaded\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T00:16:04.101611200Z",
     "start_time": "2025-12-31T00:16:04.026046100Z"
    }
   },
   "source": [
    "# Load engineered dataset (or original if feature engineering not done)\n",
    "try:\n",
    "    data = pd.read_csv('thickness_loss_dataset_engineered.csv')\n",
    "    print('✓ Loaded engineered dataset')\n",
    "except:\n",
    "    data = pd.read_csv('thickness_loss_dataset.csv')\n",
    "    print('✓ Loaded original dataset')\n",
    "\n",
    "print(f'Shape: {data.shape[0]} rows, {data.shape[1]} columns')\n",
    "data.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded engineered dataset\n",
      "Shape: 1000 rows, 25 columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Pipe_Size_mm  Thickness_mm      Material              Grade  \\\n",
       "0           800         15.48  Carbon Steel  ASTM A333 Grade 6   \n",
       "1           800         22.00           PVC  ASTM A106 Grade B   \n",
       "2           400         12.05  Carbon Steel         API 5L X52   \n",
       "3          1500         38.72  Carbon Steel         API 5L X42   \n",
       "4          1500         24.32          HDPE         API 5L X65   \n",
       "\n",
       "   Max_Pressure_psi  Temperature_C  Corrosion_Impact_Percent  \\\n",
       "0               300           84.9                     16.04   \n",
       "1               150           14.1                      7.38   \n",
       "2              2500            0.6                      2.12   \n",
       "3              1500           52.7                      5.58   \n",
       "4              1500           11.7                     12.29   \n",
       "\n",
       "   Thickness_Loss_mm  Material_Loss_Percent  Time_Years  ...  \\\n",
       "0               4.91                  31.72           2  ...   \n",
       "1               7.32                  33.27           4  ...   \n",
       "2               6.32                  52.45           7  ...   \n",
       "3               6.20                  16.01          19  ...   \n",
       "4               8.58                  35.28          20  ...   \n",
       "\n",
       "  Pressure_to_Thickness_Ratio  Corrosion_Time_Interaction  \\\n",
       "0                   19.379845                       32.08   \n",
       "1                    6.818182                       29.52   \n",
       "2                  207.468880                       14.84   \n",
       "3                   38.739669                      106.02   \n",
       "4                   61.677632                      245.80   \n",
       "\n",
       "   Temp_Pressure_Interaction  Pipe_Size_Category  Temperature_Category  \\\n",
       "0                    25470.0               Large                Medium   \n",
       "1                     2115.0               Large                   Low   \n",
       "2                     1500.0              Medium                   Low   \n",
       "3                    79050.0         Extra_Large                Medium   \n",
       "4                    17550.0         Extra_Large                   Low   \n",
       "\n",
       "   Pressure_Category  Age_Category  Critical_Threshold_Flag  \\\n",
       "0                Low           New                        0   \n",
       "1                Low           New                        0   \n",
       "2          Very_High        Mature                        1   \n",
       "3               High           Old                        0   \n",
       "4               High           Old                        0   \n",
       "\n",
       "  High_Corrosion_Flag High_Pressure_Flag  \n",
       "0                   1                  0  \n",
       "1                   0                  0  \n",
       "2                   0                  1  \n",
       "3                   0                  0  \n",
       "4                   0                  0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipe_Size_mm</th>\n",
       "      <th>Thickness_mm</th>\n",
       "      <th>Material</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Max_Pressure_psi</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Corrosion_Impact_Percent</th>\n",
       "      <th>Thickness_Loss_mm</th>\n",
       "      <th>Material_Loss_Percent</th>\n",
       "      <th>Time_Years</th>\n",
       "      <th>...</th>\n",
       "      <th>Pressure_to_Thickness_Ratio</th>\n",
       "      <th>Corrosion_Time_Interaction</th>\n",
       "      <th>Temp_Pressure_Interaction</th>\n",
       "      <th>Pipe_Size_Category</th>\n",
       "      <th>Temperature_Category</th>\n",
       "      <th>Pressure_Category</th>\n",
       "      <th>Age_Category</th>\n",
       "      <th>Critical_Threshold_Flag</th>\n",
       "      <th>High_Corrosion_Flag</th>\n",
       "      <th>High_Pressure_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>15.48</td>\n",
       "      <td>Carbon Steel</td>\n",
       "      <td>ASTM A333 Grade 6</td>\n",
       "      <td>300</td>\n",
       "      <td>84.9</td>\n",
       "      <td>16.04</td>\n",
       "      <td>4.91</td>\n",
       "      <td>31.72</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>19.379845</td>\n",
       "      <td>32.08</td>\n",
       "      <td>25470.0</td>\n",
       "      <td>Large</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Low</td>\n",
       "      <td>New</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>800</td>\n",
       "      <td>22.00</td>\n",
       "      <td>PVC</td>\n",
       "      <td>ASTM A106 Grade B</td>\n",
       "      <td>150</td>\n",
       "      <td>14.1</td>\n",
       "      <td>7.38</td>\n",
       "      <td>7.32</td>\n",
       "      <td>33.27</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>29.52</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>Large</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>New</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>12.05</td>\n",
       "      <td>Carbon Steel</td>\n",
       "      <td>API 5L X52</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.12</td>\n",
       "      <td>6.32</td>\n",
       "      <td>52.45</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>207.468880</td>\n",
       "      <td>14.84</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Low</td>\n",
       "      <td>Very_High</td>\n",
       "      <td>Mature</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500</td>\n",
       "      <td>38.72</td>\n",
       "      <td>Carbon Steel</td>\n",
       "      <td>API 5L X42</td>\n",
       "      <td>1500</td>\n",
       "      <td>52.7</td>\n",
       "      <td>5.58</td>\n",
       "      <td>6.20</td>\n",
       "      <td>16.01</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>38.739669</td>\n",
       "      <td>106.02</td>\n",
       "      <td>79050.0</td>\n",
       "      <td>Extra_Large</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>Old</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500</td>\n",
       "      <td>24.32</td>\n",
       "      <td>HDPE</td>\n",
       "      <td>API 5L X65</td>\n",
       "      <td>1500</td>\n",
       "      <td>11.7</td>\n",
       "      <td>12.29</td>\n",
       "      <td>8.58</td>\n",
       "      <td>35.28</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>61.677632</td>\n",
       "      <td>245.80</td>\n",
       "      <td>17550.0</td>\n",
       "      <td>Extra_Large</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>Old</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T00:16:04.296544100Z",
     "start_time": "2025-12-31T00:16:04.178075500Z"
    }
   },
   "source": [
    "# Define target variable\n",
    "target = 'Condition'\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=[target])\n",
    "y = data[target]\n",
    "\n",
    "print(f'Features (X): {X.shape[1]} columns')\n",
    "print(f'Target (y): {y.name}')\n",
    "print(f'\\nTarget distribution:')\n",
    "print(y.value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X): 24 columns\n",
      "Target (y): Condition\n",
      "\n",
      "Target distribution:\n",
      "Condition\n",
      "Critical    487\n",
      "Moderate    299\n",
      "Normal      214\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T00:16:04.557828500Z",
     "start_time": "2025-12-31T00:16:04.524751200Z"
    }
   },
   "source": [
    "# Encode categorical variables if needed\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    print(f'Encoding {len(categorical_cols)} categorical columns:')\n",
    "    print(categorical_cols)\n",
    "    \n",
    "    # Label encoding for categorical features\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "    \n",
    "    print('✓ Categorical features encoded')\n",
    "else:\n",
    "    print('No categorical columns to encode')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding 6 categorical columns:\n",
      "['Material', 'Grade', 'Pipe_Size_Category', 'Temperature_Category', 'Pressure_Category', 'Age_Category']\n",
      "✓ Categorical features encoded\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T00:16:04.905910700Z",
     "start_time": "2025-12-31T00:16:04.872889600Z"
    }
   },
   "source": [
    "# Encode target variable\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)\n",
    "\n",
    "print('Target encoding:')\n",
    "for i, label in enumerate(le_target.classes_):\n",
    "    print(f'  {label} → {i}')\n",
    "\n",
    "# Store mapping for later\n",
    "target_mapping = dict(zip(le_target.classes_, le_target.transform(le_target.classes_)))\n",
    "print(f'\\nMapping: {target_mapping}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target encoding:\n",
      "  Critical → 0\n",
      "  Moderate → 1\n",
      "  Normal → 2\n",
      "\n",
      "Mapping: {'Critical': np.int64(0), 'Moderate': np.int64(1), 'Normal': np.int64(2)}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train/Test Split (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T00:16:04.964477900Z",
     "start_time": "2025-12-31T00:16:04.908916Z"
    }
   },
   "source": [
    "# Perform train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded  # Maintain class distribution\n",
    ")\n",
    "\n",
    "print('✓ Train/Test split completed')\n",
    "print(f'\\nSplit ratio: 80/20')\n",
    "print(f'Random state: 42')\n",
    "print(f'Stratified: Yes (maintains class balance)')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Train/Test split completed\n",
      "\n",
      "Split ratio: 80/20\n",
      "Random state: 42\n",
      "Stratified: Yes (maintains class balance)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Verify Split"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T00:16:05.002798700Z",
     "start_time": "2025-12-31T00:16:04.973476900Z"
    }
   },
   "source": [
    "# Display split sizes\n",
    "print('Dataset Sizes:')\n",
    "print('='*60)\n",
    "print(f'Total samples: {len(X)}')\n",
    "print(f'\\nTraining set: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)')\n",
    "print(f'Test set:     {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)')\n",
    "print(f'\\nFeatures: {X_train.shape[1]}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes:\n",
      "============================================================\n",
      "Total samples: 1000\n",
      "\n",
      "Training set: 800 samples (80.0%)\n",
      "Test set:     200 samples (20.0%)\n",
      "\n",
      "Features: 24\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T00:16:05.044116900Z",
     "start_time": "2025-12-31T00:16:05.004797400Z"
    }
   },
   "source": [
    "# Check class distribution in splits\n",
    "print('Class Distribution Verification:')\n",
    "print('='*60)\n",
    "\n",
    "# Original distribution\n",
    "print('\\nOriginal:')\n",
    "for label, code in target_mapping.items():\n",
    "    count = (y_encoded == code).sum()\n",
    "    pct = count / len(y_encoded) * 100\n",
    "    print(f'  {label}: {count} ({pct:.1f}%)')\n",
    "\n",
    "# Training set distribution\n",
    "print('\\nTraining set:')\n",
    "for label, code in target_mapping.items():\n",
    "    count = (y_train == code).sum()\n",
    "    pct = count / len(y_train) * 100\n",
    "    print(f'  {label}: {count} ({pct:.1f}%)')\n",
    "\n",
    "# Test set distribution\n",
    "print('\\nTest set:')\n",
    "for label, code in target_mapping.items():\n",
    "    count = (y_test == code).sum()\n",
    "    pct = count / len(y_test) * 100\n",
    "    print(f'  {label}: {count} ({pct:.1f}%)')\n",
    "\n",
    "print('\\n✓ Class distribution maintained across splits')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution Verification:\n",
      "============================================================\n",
      "\n",
      "Original:\n",
      "  Critical: 487 (48.7%)\n",
      "  Moderate: 299 (29.9%)\n",
      "  Normal: 214 (21.4%)\n",
      "\n",
      "Training set:\n",
      "  Critical: 390 (48.8%)\n",
      "  Moderate: 239 (29.9%)\n",
      "  Normal: 171 (21.4%)\n",
      "\n",
      "Test set:\n",
      "  Critical: 97 (48.5%)\n",
      "  Moderate: 60 (30.0%)\n",
      "  Normal: 43 (21.5%)\n",
      "\n",
      "✓ Class distribution maintained across splits\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Split Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T00:16:05.159452300Z",
     "start_time": "2025-12-31T00:16:05.057119200Z"
    }
   },
   "source": [
    "# Save train/test sets\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "pd.DataFrame(y_train, columns=['Condition']).to_csv('y_train.csv', index=False)\n",
    "pd.DataFrame(y_test, columns=['Condition']).to_csv('y_test.csv', index=False)\n",
    "\n",
    "print('✓ Saved files:')\n",
    "print('  - X_train.csv')\n",
    "print('  - X_test.csv')\n",
    "print('  - y_train.csv')\n",
    "print('  - y_test.csv')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved files:\n",
      "  - X_train.csv\n",
      "  - X_test.csv\n",
      "  - y_train.csv\n",
      "  - y_test.csv\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T00:16:06.575245400Z",
     "start_time": "2025-12-31T00:16:05.180455500Z"
    }
   },
   "source": [
    "# Save target mapping for reference\n",
    "import json\n",
    "\n",
    "with open('target_mapping.json', 'w') as f:\n",
    "    json.dump(target_mapping, f, indent=2)\n",
    "\n",
    "print('✓ Saved target_mapping.json')\n",
    "print(f'  Mapping: {target_mapping}')"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mjson\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mtarget_mapping.json\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mw\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     \u001B[43mjson\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget_mapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindent\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33m✓ Saved target_mapping.json\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33m  Mapping: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget_mapping\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\json\\__init__.py:179\u001B[39m, in \u001B[36mdump\u001B[39m\u001B[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001B[39m\n\u001B[32m    173\u001B[39m     iterable = \u001B[38;5;28mcls\u001B[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001B[32m    174\u001B[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001B[32m    175\u001B[39m         separators=separators,\n\u001B[32m    176\u001B[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001B[32m    177\u001B[39m \u001B[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001B[39;00m\n\u001B[32m    178\u001B[39m \u001B[38;5;66;03m# a debuggability cost\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m179\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\json\\encoder.py:432\u001B[39m, in \u001B[36m_make_iterencode.<locals>._iterencode\u001B[39m\u001B[34m(o, _current_indent_level)\u001B[39m\n\u001B[32m    430\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m _iterencode_list(o, _current_indent_level)\n\u001B[32m    431\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(o, \u001B[38;5;28mdict\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m432\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m _iterencode_dict(o, _current_indent_level)\n\u001B[32m    433\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    434\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m markers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\json\\encoder.py:406\u001B[39m, in \u001B[36m_make_iterencode.<locals>._iterencode_dict\u001B[39m\u001B[34m(dct, _current_indent_level)\u001B[39m\n\u001B[32m    404\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    405\u001B[39m             chunks = _iterencode(value, _current_indent_level)\n\u001B[32m--> \u001B[39m\u001B[32m406\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m chunks\n\u001B[32m    407\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m newline_indent \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    408\u001B[39m     _current_indent_level -= \u001B[32m1\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\json\\encoder.py:439\u001B[39m, in \u001B[36m_make_iterencode.<locals>._iterencode\u001B[39m\u001B[34m(o, _current_indent_level)\u001B[39m\n\u001B[32m    437\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mCircular reference detected\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    438\u001B[39m     markers[markerid] = o\n\u001B[32m--> \u001B[39m\u001B[32m439\u001B[39m o = \u001B[43m_default\u001B[49m\u001B[43m(\u001B[49m\u001B[43mo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    440\u001B[39m \u001B[38;5;28;01myield from\u001B[39;00m _iterencode(o, _current_indent_level)\n\u001B[32m    441\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m markers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\json\\encoder.py:180\u001B[39m, in \u001B[36mJSONEncoder.default\u001B[39m\u001B[34m(self, o)\u001B[39m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdefault\u001B[39m(\u001B[38;5;28mself\u001B[39m, o):\n\u001B[32m    162\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Implement this method in a subclass such that it returns\u001B[39;00m\n\u001B[32m    163\u001B[39m \u001B[33;03m    a serializable object for ``o``, or calls the base implementation\u001B[39;00m\n\u001B[32m    164\u001B[39m \u001B[33;03m    (to raise a ``TypeError``).\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    178\u001B[39m \n\u001B[32m    179\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m180\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mObject of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mo.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    181\u001B[39m                     \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mis not JSON serializable\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mTypeError\u001B[39m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Split Configuration:\n",
    "- **Train/Test Ratio:** 80/20\n",
    "- **Random State:** 42 (reproducible)\n",
    "- **Stratification:** Yes (maintains class balance)\n",
    "\n",
    "### Dataset Sizes:\n",
    "- **Training:** 800 samples\n",
    "- **Test:** 200 samples\n",
    "- **Features:** Check output above\n",
    "\n",
    "### Files Generated:\n",
    "- X_train.csv, X_test.csv\n",
    "- y_train.csv, y_test.csv\n",
    "- target_mapping.json\n",
    "\n",
    "### Next Steps:\n",
    "1. Feature scaling (if needed)\n",
    "2. Train baseline models\n",
    "3. Evaluate performance\n",
    "\n",
    "---\n",
    "**Train/Test Split Complete!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
